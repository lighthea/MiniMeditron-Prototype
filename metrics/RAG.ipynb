{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cb4421e2be4dbfb7383d2a5caccae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a25ea724fb3435ca206280b9aaca315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b5edd36e6949b68f316f6f06e74b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84858eb78d8c499ca89a4159eb4d4976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/492 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ecaf531cda454e92910b27d6176b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Assuming your data is structured as a list of passages in each JSON file\n",
    "texts = []\n",
    "for filename in os.listdir(\"/home/etien/Documents/EPFLcourses/MA3/Meditron/Guidelines/split_guidelines/cdc_diseases.jsonl\"):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(\"/home/etien/Documents/EPFLcourses/MA3/Meditron/Guidelines/split_guidelines/cdc_diseases.jsonl\", filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            texts.extend(data['title'])\n",
    "\n",
    "# Initialize DPR encoder and tokenizer\n",
    "tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-multiset-base')\n",
    "model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-multiset-base')\n",
    "\n",
    "\n",
    "# Encode texts\n",
    "encoded_texts = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "embeddings = model(encoded_texts['input_ids']).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Index the embeddings for fast retrieval\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fd81fa7e76404a932b11a7012a7689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etien/miniconda3/lib/python3.11/site-packages/transformers/models/bart/configuration_bart.py:179: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39be7ff8f47b486db31abcb2caa2e2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f61fc7c59e4abc9022f5f47e8a977e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_tokenizer/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72c7e1dfb2746fc8bc1ffa53ee92e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862c846c5be44208a6a53622aa32cbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6398bbecd0459f9c5ae56844229159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db214ce7b9484d0db99ebc5279239671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb17ceba5044ce098dae6fcb629af55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "/home/etien/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 2063.60 MB. The target location /home/etien/.cache/huggingface/hub only has 1839.49 MB free disk space.\n",
      "  warnings.warn(\n",
      "/home/etien/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 2063.60 MB. The target location /home/etien/.cache/huggingface/hub/models--facebook--rag-token-nq/blobs only has 1839.49 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f923ba0fa840476788865a61ec268699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/rag-token-nq were not used when initializing RagTokenForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RagTokenForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagTokenForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RagTokenizer' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m rag_model \u001b[39m=\u001b[39m RagTokenForGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/rag-token-nq\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# But with your custom retriever\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# 4. Generate answer with RAG\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m input_ids \u001b[39m=\u001b[39m rag_tokenizer\u001b[39m.\u001b[39;49mencode(question, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m generated_ids \u001b[39m=\u001b[39m rag_model\u001b[39m.\u001b[39mgenerate(input_ids\u001b[39m=\u001b[39minput_ids, context_input_ids\u001b[39m=\u001b[39mrelevant_doc_ids) \u001b[39m# This step is illustrative and the actual call might differ depending on the setup\u001b[39;00m\n\u001b[1;32m     25\u001b[0m answer \u001b[39m=\u001b[39m rag_tokenizer\u001b[39m.\u001b[39mdecode(generated_ids[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RagTokenizer' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagTokenForGeneration\n",
    "\n",
    "# 1. Given a question, use your FAISS index to retrieve the relevant document IDs:\n",
    "def get_relevant_doc_ids(question, tokenizer, model, index, k=5):\n",
    "    # Encode question\n",
    "    encoded_question = tokenizer(question, return_tensors='pt')\n",
    "    question_embedding = model(encoded_question['input_ids']).pooler_output\n",
    "    _, doc_ids = index.search(question_embedding.cpu().detach().numpy(), k)\n",
    "    return doc_ids[0]\n",
    "\n",
    "# Dummy function to simulate the retrieval\n",
    "question = \"What are the symptoms of cholera?\"\n",
    "relevant_doc_ids = get_relevant_doc_ids(question, tokenizer, model, index)\n",
    "\n",
    "# 2. Extend the RagRetriever to use your custom retriever:\n",
    "# ... (This can be complex and might require adapting the existing RagRetriever class)\n",
    "\n",
    "# 3. Initialize RAG with your custom retriever\n",
    "rag_tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "rag_model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\") # But with your custom retriever\n",
    "\n",
    "# 4. Generate answer with RAG\n",
    "input_ids = rag_tokenizer.encode(question, return_tensors=\"pt\")\n",
    "generated_ids = rag_model.generate(input_ids=input_ids, context_input_ids=relevant_doc_ids) # This step is illustrative and the actual call might differ depending on the setup\n",
    "answer = rag_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Your question here\"\n",
    "input_dict = rag_tokenizer.prepare_seq2seq_batch(question, return_tensors=\"pt\")\n",
    "outputs = model.generate(**input_dict)\n",
    "answer = rag_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
