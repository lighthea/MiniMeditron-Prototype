{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that you have the correct embeddings and create the structure around it.\n",
    "\n",
    "Need to check what is the structure of the embeddings with Nanogpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tensor_distance(tensor1, tensor2, distance_type=\"L2\"):\n",
    "    \"\"\"\n",
    "    Compute the L2 (Euclidean) distance between two tensors of the same shape.\n",
    "    \n",
    "    Args:\n",
    "    - tensor1 (torch.Tensor): The first tensor.\n",
    "    - tensor2 (torch.Tensor): The second tensor.\n",
    "    - distance_type (str): The type of distance to compute. Currently only\n",
    "    \n",
    "    Returns:\n",
    "    - float: The distance / similarity between the two tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    if tensor1.shape != tensor2.shape:\n",
    "        raise ValueError(\"Both tensors must have the same shape.\")\n",
    "\n",
    "    if distance_type == \"L2\":\n",
    "        distance = torch.norm(tensor1 - tensor2)\n",
    "    elif distance_type == \"Manhattan\":\n",
    "        distance = torch.sum(torch.abs(tensor1 - tensor2))\n",
    "    elif distance_type == \"Cosine\":\n",
    "        similarity = F.cosine_similarity(tensor1, tensor2)\n",
    "        distance = 1 - similarity\n",
    "    elif distance_type == \"Minkowski\":\n",
    "        distance = torch.norm(tensor1 - tensor2, p=3)\n",
    "    \n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between tensor_a and tensor_b: tensor(2.7149)\n",
      "Manhattan distance between tensor_a and tensor_b: tensor(13.8901)\n",
      "Cosine distance between tensor_a and tensor_b: tensor([[0.1610, 0.0945, 0.3316, 0.0607, 0.0029, 0.1343, 0.0566, 0.2987, 0.0584,\n",
      "         0.2001, 0.3942, 0.0090, 0.0996, 0.4831, 0.0473]])\n",
      "Minkowski distance between tensor_a and tensor_b: tensor(1.6951)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "tensor_a = torch.rand((1, 3, 15))\n",
    "tensor_b = torch.rand((1, 3, 15)) \n",
    "\n",
    "distance_types = [\"L2\", \"Manhattan\", \"Cosine\", \"Minkowski\"]\n",
    "\n",
    "for dist in distance_types:\n",
    "    print(f\"{dist} distance between tensor_a and tensor_b:\", tensor_distance(tensor_a, tensor_b, dist))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports\n",
    "\n",
    "# from transformers import pipeline\n",
    "# import torch\n",
    "\n",
    "# import os\n",
    "# import torch\n",
    "# from model import GPT, GPTConfig\n",
    "\n",
    "# from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# generator = pipeline(\"text-generation\")\n",
    "# res = generator(\"dommage\")\n",
    "\n",
    "# %run '/home/etien/Documents/EPFLcourses/MA3/Meditron/nanoGPT/model.py'\n",
    "\n",
    "# def load_model(checkpoint_path=None, config=None):\n",
    "#     \"\"\"\n",
    "#     Load the GPT model. If a checkpoint path is provided, load weights from the checkpoint.\n",
    "    \n",
    "#     Args:\n",
    "#     - checkpoint_path (str, optional): Path to the model checkpoint.\n",
    "#     - config (GPTConfig, optional): Configuration for the model. If not provided, uses the default configuration.\n",
    "\n",
    "#     Returns:\n",
    "#     - model (GPT): The instantiated model.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Use the provided config or create a default one\n",
    "#     if config is None:\n",
    "#         config = GPTConfig()\n",
    "\n",
    "#     # Instantiate the model\n",
    "#     model = GPT(config)\n",
    "\n",
    "#     # If a saved checkpoint is provided, load it\n",
    "#     if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "#         checkpoint = torch.load(checkpoint_path)\n",
    "#         model.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Usage\n",
    "# model = load_model(\"/home/etien/Documents/EPFLcourses/MA3/Meditron/nanoGPT/checkpoint/checkpoint.ckpt\")\n",
    "\n",
    "# torch.save(model.state_dict(), \"/home/etien/Documents/EPFLcourses/MA3/Meditron/nanoGPT/checkpoint/checkpoint.ckpt\")\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# model.generate(\"Bonjour\", max_length=100, do_sample=True, temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
