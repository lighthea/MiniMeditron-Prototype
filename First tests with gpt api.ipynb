{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a30c6469",
   "metadata": {},
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379c8b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPEN_AI_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPEN_AI_KEY = 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5965a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/etien/miniconda3/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: wandb in /home/etien/miniconda3/lib/python3.11/site-packages (0.15.12)\n",
      "Requirement already satisfied: requests>=2.20 in /home/etien/miniconda3/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/etien/miniconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /home/etien/miniconda3/lib/python3.11/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (1.31.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: pathtools in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (67.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/etien/miniconda3/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/etien/miniconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/etien/miniconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/etien/miniconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/etien/miniconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/etien/miniconda3/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/etien/miniconda3/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/etien/miniconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/etien/miniconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/etien/miniconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/etien/miniconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aaedccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332593dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33metiennalphat\u001b[0m (\u001b[33mbastiteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/etien/Documents/EPFLcourses/MA3/Meditron/wandb/run-20231017_130134-zam12enm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bastiteam/GPT-4%20in%20Python/runs/zam12enm' target=\"_blank\">giddy-blaze-5</a></strong> to <a href='https://wandb.ai/bastiteam/GPT-4%20in%20Python' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bastiteam/GPT-4%20in%20Python' target=\"_blank\">https://wandb.ai/bastiteam/GPT-4%20in%20Python</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bastiteam/GPT-4%20in%20Python/runs/zam12enm' target=\"_blank\">https://wandb.ai/bastiteam/GPT-4%20in%20Python/runs/zam12enm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='GPT-4 in Python')\n",
    "prediction_table = wandb.Table(columns=[\"prompt\", \"prompt tokens\", \"completion\", \"completion tokens\", \"model\", \"total tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ffb30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "instruction = \"\"\"Using the provided medical guideline, craft a doctor's description of a patient. The description should detail symptoms from the guideline without explicitly naming the disease. You can enhance the authenticity of the description by incorporating the patient's pain levels related to symptoms, lifestyle, medical history, and any previously applied treatments. While you may introduce supplementary symptoms, they should be relevant and factual and the overall description should remain concise.\\n\"\"\"\n",
    "\n",
    "file_list = os.listdir(\"Guidelines/split_guidelines/wikidoc.jsonl\")\n",
    "\n",
    "num_smallest_files = int(len(file_list) * 0.1)\n",
    "\n",
    "sorted_files = sorted(file_list, key=lambda x: os.path.getsize(os.path.join(\"Guidelines/split_guidelines/wikidoc.jsonl\", x)))\n",
    "\n",
    "if num_smallest_files >= 10:\n",
    "    smallest_files = random.sample(sorted_files[:num_smallest_files], 10)\n",
    "else:\n",
    "    print(\"There are not enough small files to select 10 random files.\")\n",
    "\n",
    "prompt_tab = []\n",
    "\n",
    "for name in smallest_files:\n",
    "    with open(\"Guidelines/split_guidelines/wikidoc.jsonl/\" + name) as f:\n",
    "        guideline = f.read()\n",
    "    prompt_tab += [instruction + guideline]\n",
    "\n",
    "# save smallest_files in a txt file\n",
    "with open(\"smallest_files.txt\", \"w\") as f:\n",
    "    for name in smallest_files:\n",
    "        f.write(name + \"\\n\")\n",
    "\n",
    "print(len(prompt_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4c906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a485a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tab = []\n",
    "\n",
    "for prompt in prompt_tab:\n",
    "    message=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages = message,\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000,\n",
    "        frequency_penalty=0.0\n",
    "    )\n",
    "    response_tab += [response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1b7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Generated_descriptions folder if it doesn't exist\n",
    "if not os.path.exists(\"Generated_descriptions\"):\n",
    "    os.makedirs(\"Generated_descriptions\")\n",
    "\n",
    "# from response_tab to save to file\n",
    "for i in range(len(response_tab)):\n",
    "    with open(\"Generated_descriptions/\" + str(i) + \".txt\", \"w\") as f:\n",
    "        f.write(response_tab[i][\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79d5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt_tab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompt_tab:\n\u001b[1;32m      2\u001b[0m     prediction_table \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39mTable(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mPrompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mResponse\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTokens\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m     prediction_table\u001b[39m.\u001b[39madd_data(prompt,response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m],response[\u001b[39m'\u001b[39m\u001b[39musage\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt_tab' is not defined"
     ]
    }
   ],
   "source": [
    "for prompt in prompt_tab:\n",
    "    prediction_table = wandb.Table(columns=[\"Prompt\", \"Response\", \"Tokens\"])\n",
    "    prediction_table.add_data(prompt,response['choices'][0],response['usage'])\n",
    "    wandb.log({'predictions': prediction_table})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfab7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the wandb storage\n",
    "wandb.restore('wandb/latest-run/files/predictions_table.jsonl', run_path='GPT-4 in Python/2j1q2q7i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbdd427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
